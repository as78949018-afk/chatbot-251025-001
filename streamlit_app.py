# app.py
import os, io, json
import numpy as np
import streamlit as st
from openai import OpenAI

# ì˜ˆì™¸ í´ë˜ìŠ¤(í™˜ê²½ë³„ ê°€ë“œ)
try:
    from openai import APIError, RateLimitError, AuthenticationError
except Exception:
    APIError = RateLimitError = AuthenticationError = Exception

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
try:
    import PyPDF2
    HAS_PYPDF2 = True
except Exception:
    HAS_PYPDF2 = False

# ----------------------------
# í˜ì´ì§€ ì„¤ì •
# ----------------------------
st.set_page_config(page_title="ì•„ì´ë””ì–´ ì±—ë´‡", page_icon="ğŸ¤", layout="wide")

# ----------------------------
# ì „ì—­ ìŠ¤íƒ€ì¼ (ìƒë‹¨ë°” ê³ ì • ì—†ìŒ)
# ----------------------------
st.markdown("""
<style>
:root{
  --brand:#F4D24B;  /* ë…¸ë€ í¬ì¸íŠ¸ */
  --ink:#222; --ink-weak:#5f6368;
  --bg:#F6F7F9; --card:#fff; --line:rgba(0,0,0,.08); --muted:#EEF0F4;
  --r-lg:18px; --r-xl:24px;
}
html, body, [data-testid="stAppViewContainer"]{
  background:var(--bg);
  color:var(--ink);
  font-family: Pretendard, Inter, ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, "Noto Sans KR", "Malgun Gothic", sans-serif;
}
.block-container{
  padding-top: 6rem !important;   /* â† ìƒë‹¨ ì—¬ë°± í¬ê²Œ */
  padding-bottom: 2.5rem !important;
}

/* ì‚¬ì´ë“œë°” í†¤ */
[data-testid="stSidebar"]{
  background:var(--brand) !important;
  border-right:1px solid rgba(0,0,0,.12);
}
[data-testid="stSidebar"] *{ color:#1d1d1d !important; }

/* ì¹´ë“œ/ë°°ì§€ */
.card{
  background:var(--card);
  border:1px solid var(--line);
  border-radius: var(--r-xl);
  box-shadow: 0 8px 20px rgba(0,0,0,.05);
  padding: 16px 18px;
}
.badge{
  display:inline-flex; gap:6px; align-items:center;
  background:var(--muted);
  border:1px solid var(--line);
  border-radius: 999px;
  padding: 4px 10px;
  font-size:12px; color:#444;
}

/* ìƒë‹¨ í—¤ë” í–‰ */
.header{
  display:flex; align-items:center; justify-content:space-between; gap:12px;
}

/* ì…ë ¥ ì¹´ë“œ */
textarea{
  font-size:18px !important; line-height:1.55 !important;
}
.send-btn{
  background:#231F20; color:#fff; border:none; border-radius:999px;
  padding:12px 18px; font-weight:700;
}

/* ë§í’ì„  */
.msg{ display:flex; gap:10px; margin:10px 0;}
.bubble{ background:#fff; border:1px solid var(--line); border-radius:18px; padding:12px 14px;}
.user .bubble{ background:#F8FAFF; border-color:rgba(91,141,239,.35); }
.assistant .bubble{ background:#fff; }
.avatar{ width:30px;height:30px;border-radius:50%; background:var(--muted);
  display:flex;align-items:center;justify-content:center;}
.hr{ border:none; height:1px; background:var(--line); margin:16px 0 10px; }

/* popover ì•ˆ ë²„íŠ¼ ê°€ë…ì„± */
[data-testid="stPopoverContent"] .stButton>button{ width:100%; }
</style>
""", unsafe_allow_html=True)

# ----------------------------
# ì„¸ì…˜ ê¸°ë³¸ê°’
# ----------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []           # [{"role": "system|user|assistant", "content": "..."}]
    st.session_state.has_system = False
st.session_state.setdefault("rag_ready", False)
st.session_state.setdefault("rag_chunks", [])
st.session_state.setdefault("rag_embeds", None)    # np.array(N,D)
st.session_state.setdefault("rag_model", "text-embedding-3-small")
st.session_state.setdefault("use_rag", False)
st.session_state.setdefault("show_upload", False)

# ----------------------------
# ë„ìš°ë¯¸ í•¨ìˆ˜
# ----------------------------
def ensure_system_message(prompt_text: str):
    if not st.session_state.has_system:
        st.session_state.messages.insert(0, {"role":"system","content":prompt_text})
        st.session_state.has_system = True
    else:
        st.session_state.messages[0]["content"] = prompt_text

def trim_history(max_turns:int):
    msgs = st.session_state.messages
    if not msgs: return
    sys = msgs[0] if msgs and msgs[0]["role"]=="system" else None
    body = msgs[1:] if sys else msgs[:]
    limit = max_turns*2
    if len(body) > limit:
        body = body[-limit:]
    st.session_state.messages = ([sys] if sys else []) + body

def extract_text_from_pdf(file_bytes:bytes)->str:
    if not HAS_PYPDF2: return ""
    try:
        reader = PyPDF2.PdfReader(io.BytesIO(file_bytes))
        return "\n".join([(p.extract_text() or "") for p in reader.pages])
    except Exception:
        return ""

def chunk_text(text:str, chunk_size=900, overlap=200):
    text = " ".join(text.split())
    if not text: return []
    out, start = [], 0
    while start < len(text):
        end = start + chunk_size
        out.append(text[start:end])
        if end >= len(text): break
        start = max(0, end-overlap)
    return out

def cosine_sim(A:np.ndarray,B:np.ndarray):
    A = A/(np.linalg.norm(A,axis=1,keepdims=True)+1e-12)
    B = B/(np.linalg.norm(B,axis=1,keepdims=True)+1e-12)
    return A @ B.T

def build_embeddings(client:OpenAI, chunks:list[str], model:str)->np.ndarray:
    if not chunks: return np.zeros((0,1536),dtype=np.float32)
    resp = client.embeddings.create(model=model, input=chunks)
    return np.array([d.embedding for d in resp.data], dtype=np.float32)

def retrieve_context(query:str, top_k=4)->str:
    if not (st.session_state.rag_ready and st.session_state.rag_embeds is not None):
        return ""
    try:
        q = client.embeddings.create(model=st.session_state.rag_model, input=[query]).data[0].embedding
        qv = np.array([q], dtype=np.float32)
        sims = cosine_sim(qv, st.session_state.rag_embeds).flatten()
        idx = np.argsort(-sims)[:top_k]
        return "\n\n".join([st.session_state.rag_chunks[i] for i in idx])
    except Exception:
        return ""

def export_chat_as_txt(messages:list[dict])->bytes:
    lines = []
    for m in messages:
        if m.get("role") == "system": continue
        lines.append(f"[{m['role'].upper()}]\n{m.get('content','')}\n")
    return "\n".join(lines).encode("utf-8")

def export_chat_as_json(messages:list[dict])->bytes:
    payload = [m for m in messages if m.get("role") in ("user","assistant")]
    return json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8")

def render_msg(role, content):
    who = "user" if role=="user" else "assistant"
    av  = "ğŸ¤" if role=="assistant" else "ğŸ™‚"
    st.markdown(
        f'<div class="msg {who}"><div class="avatar">{av}</div>'
        f'<div class="bubble">{content}</div></div>',
        unsafe_allow_html=True
    )

# ----------------------------
# ìƒë‹¨: íƒ€ì´í‹€ + ìƒíƒœ/ë‚´ë³´ë‚´ê¸°(ì•„ì´ì½˜)
# ----------------------------
col_title, col_badges, col_menu = st.columns([6, 3, 1])
with col_title:
    st.markdown("### ğŸ¤ **ì•„ì´ë””ì–´ ì±—ë´‡**")
with col_badges:
    # ë°°ì§€ëŠ” ì‚¬ì´ë“œë°”ì—ì„œ ê°’ ì–»ì€ ë’¤ ì±„ì›€(ì•„ë˜ì—ì„œ ê°±ì‹ )
    pass
with col_menu:
    pop = st.popover("ğŸ“¥", use_container_width=True)
    with pop:
        st.markdown("**ëŒ€í™” ë‚´ë³´ë‚´ê¸°**")
        st.download_button("TXTë¡œ ì €ì¥", data=export_chat_as_txt(st.session_state.messages),
                           file_name="chat.txt", mime="text/plain", use_container_width=True)
        st.download_button("JSONìœ¼ë¡œ ì €ì¥", data=export_chat_as_json(st.session_state.messages),
                           file_name="chat.json", mime="application/json", use_container_width=True)

# ----------------------------
# ì‚¬ì´ë“œë°”: ì„¤ì •
# ----------------------------
with st.sidebar:
    st.header("ì„¤ì •")
    default_key = os.environ.get("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", None)
    openai_api_key = st.text_input("OpenAI API Key", type="password", value=default_key or "")
    model = st.selectbox("ëª¨ë¸", ["gpt-4o", "gpt-4o-mini"], index=0)
    temperature = st.slider("ì°½ì˜ì„±(temperature)", 0.0, 1.2, 0.7, 0.1)
    max_output_tokens = st.slider("ì‘ë‹µ ê¸¸ì´(max tokens)", 64, 4096, 1024, 64)
    stream_enable = st.toggle("ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°", value=True)
    st.markdown("---")
    preset = st.selectbox("ë§íˆ¬/ì—­í•  í”„ë¦¬ì…‹", ["ê¸°ë³¸","ì¹œì ˆí•œ íŠœí„°","ì´ˆê°„ë‹¨ ìš”ì•½ë´‡","ë¬¸ì¥ ë‹¤ë“¬ê¸°(êµì •)"])
    preset_map = {
        "ê¸°ë³¸":"You are a helpful, concise assistant.",
        "ì¹œì ˆí•œ íŠœí„°":"You are a friendly tutor. Explain step-by-step with small, clear paragraphs and examples.",
        "ì´ˆê°„ë‹¨ ìš”ì•½ë´‡":"You summarize any input into 3 bullet points with the most essential facts only.",
        "ë¬¸ì¥ ë‹¤ë“¬ê¸°(êµì •)":"Rewrite the user's text with improved clarity, grammar, and natural tone while preserving meaning."
    }
    system_prompt = st.text_area("System prompt(ì„¸ë¶€ ì¡°ì • ê°€ëŠ¥)", value=preset_map[preset], height=100)
    st.markdown("---")
    max_turns_keep = st.slider("íˆìŠ¤í† ë¦¬ ë³´ì¡´ í„´(ì§ˆë¬¸/ë‹µë³€ ìŒ)", 5, 60, 30, 1)
    reset = st.button("ğŸ”„ ìƒˆ ëŒ€í™” ì‹œì‘", use_container_width=True)

if reset:
    st.session_state.clear()
    st.rerun()

# ìƒë‹¨ ë°°ì§€ ê°±ì‹ 
with col_badges:
    st.markdown(
        f'<span class="badge">Model: <b>{model}</b></span> '
        f'<span class="badge">Temp: <b>{float(temperature):.2f}</b></span>',
        unsafe_allow_html=True
    )

# ì•ˆë‚´ (í‚¤ ì—†ì„ ë•Œ)
if not openai_api_key:
    st.info("ğŸ”‘ **ì‚¬ì´ë“œë°”ì— OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.** (ì—†ì–´ë„ UIëŠ” ì‚¬ìš© ê°€ëŠ¥)", icon="ğŸ—ï¸")

# í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key=openai_api_key) if openai_api_key else None
no_key = not bool(openai_api_key)

# ----------------------------
# ì„¤ëª…(ì ‘ê¸°)
# ----------------------------
with st.expander("ì„¤ëª… ë³´ê¸°", expanded=False):
    st.markdown(
        "- OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. API í‚¤ëŠ” ì„¸ì…˜ì—ì„œë§Œ ì“°ì´ê³  ì„œë²„ì— ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
        "- ë°°í¬ ì‹œ **í™˜ê²½ë³€ìˆ˜** ë˜ëŠ” **Streamlit Secrets** ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
        "- ì—…ë¡œë“œ íŒŒì¼(PDF/TXT)ì€ ì„¸ì…˜ ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤."
    )

# ----------------------------
# ğŸ“ íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ) â€” PDF/TXT ì§€ì›, ì§ˆì˜ ì‘ë‹µì— í™œìš© (í† ê¸€)
# ----------------------------
st.session_state.show_upload = st.toggle("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ) â€” PDF/TXT ì§€ì›, ì§ˆì˜ ì‘ë‹µì— í™œìš© ì—´ê¸°",
                                         value=st.session_state.show_upload,
                                         help="ë„ë©´ ì—…ë¡œë“œ/RAG UIê°€ ìˆ¨ê²¨ì§‘ë‹ˆë‹¤.")
if st.session_state.show_upload:
    st.markdown('<div class="card">', unsafe_allow_html=True)

    uploaded_files = st.file_uploader(
    "",
    type=["pdf","txt"],
    accept_multiple_files=True,
    label_visibility="collapsed",
    help="PDFë‚˜ TXTë¥¼ ì˜¬ë¦¬ë©´, ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ í’ˆì§ˆì´ í–¥ìƒë¼ìš”. ì—¬ëŸ¬ íŒŒì¼ ê°€ëŠ¥."
    )

    left, right = st.columns([3,2])
    with left:
        st.session_state.use_rag = st.toggle(
            "RAG ì‚¬ìš©",
            value=st.session_state.get("use_rag", False),
            help="ì¼œë©´ ì—…ë¡œë“œ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©í•©ë‹ˆë‹¤."
        )
    with right:
        _pad, btn = st.columns([1,1])
        with btn:
            rebuild = st.button("ğŸ“š ì¸ë±ìŠ¤ ìƒì„±/ì¬ìƒì„±", use_container_width=True)

    if rebuild and uploaded_files:
        if no_key:
            st.error("ì„ë² ë”© ìƒì„±ì—ëŠ” API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ğŸ”‘")
        else:
            all_text=[]
            for f in uploaded_files:
                if f.type=="text/plain" or f.name.lower().endswith(".txt"):
                    text = f.read().decode("utf-8", errors="ignore")
                elif f.type=="application/pdf" or f.name.lower().endswith(".pdf"):
                    if not HAS_PYPDF2:
                        st.warning(f"'{f.name}': PyPDF2 ë¯¸ì„¤ì¹˜ë¡œ PDF ì¶”ì¶œ ë¶ˆê°€(TXTë§Œ ì§€ì›).")
                        text = ""
                    else:
                        text = extract_text_from_pdf(f.read())
                else:
                    text = ""
                if text: all_text.append(text)

            full_text = "\n\n".join(all_text)
            chunks = chunk_text(full_text, chunk_size=900, overlap=200)

            if not chunks:
                st.warning("ì¶”ì¶œ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤ìº” PDFëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ì„ ìˆ˜ ìˆì–´ìš”.")
            else:
                with st.spinner("ì„ë² ë”© ìƒì„± ì¤‘â€¦"):
                    vecs = build_embeddings(client, chunks, st.session_state.rag_model)
                st.session_state.rag_chunks = chunks
                st.session_state.rag_embeds = vecs
                st.session_state.rag_ready = True
                st.success(f"ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ! ì²­í¬ {len(chunks)}ê°œ")

    st.markdown('</div>', unsafe_allow_html=True)
else:
    # ë‹«í ë•Œ ì„ íƒì ìœ¼ë¡œ ì´ˆê¸°í™”
    st.session_state.rag_ready = False
    st.session_state.rag_chunks = []
    st.session_state.rag_embeds = None

# ----------------------------
# ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ë Œë”ë§
# ----------------------------
for m in st.session_state.messages:
    if m["role"] in ("user","assistant"):
        render_msg(m["role"], m["content"])

if not st.session_state.messages:
    st.markdown('<div class="card">â“ ë¨¼ì € ì§ˆë¬¸ì„ ì…ë ¥í•´ ë³´ì„¸ìš”. ì˜ˆ) "ì´ PDFì˜ í•µì‹¬ ìš”ì•½ 3ì¤„"</div>', unsafe_allow_html=True)

# ----------------------------
# ì…ë ¥ (ì´ë¯¸ì§€ ë²„íŠ¼ ì œê±°, ì „ì†¡ë§Œ)
# ----------------------------
with st.container():
    st.markdown('<div class="card">', unsafe_allow_html=True)
    with st.form("prompt_form", clear_on_submit=False):
        user_input = st.text_area(
            "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
            value="",
            height=160,
            label_visibility="collapsed",
            placeholder="ì•„ì´ë””ì–´ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”. (Shift+Enter ì¤„ë°”ê¿ˆ)"
        )
        cols = st.columns([10,2])
        with cols[1]:
            submitted = st.form_submit_button("âœ", use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)

# ----------------------------
# ìƒì„±/ì‘ë‹µ
# ----------------------------
if submitted and user_input.strip():
    ensure_system_message(system_prompt)
    trim_history(max_turns_keep)

    st.session_state.messages.append({"role":"user","content":user_input})
    render_msg("user", user_input)

    # RAG ì»¨í…ìŠ¤íŠ¸
    additional_context = ""
    if st.session_state.get("use_rag", False):
        ctx = retrieve_context(user_input, top_k=4)
        if ctx:
            additional_context = (
                "You may use the following context extracted from the user's documents. "
                "If it is relevant, ground your answer in it. If not, ignore it.\n\n"
                f"=== BEGIN CONTEXT ===\n{ctx}\n=== END CONTEXT ==="
            )

    try:
        call_messages = list(st.session_state.messages)
        if additional_context:
            call_messages.append({"role":"user","content":additional_context})

        if no_key:
            reply = "ğŸ”’ ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ: ì‚¬ì´ë“œë°”ì— API Keyë¥¼ ì…ë ¥í•˜ë©´ ì‹¤ì œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."
            st.session_state.messages.append({"role":"assistant","content":reply})
            render_msg("assistant", reply)
        else:
            if stream_enable:
                with st.spinner("ìƒì„± ì¤‘â€¦"):
                    stream = client.chat.completions.create(
                        model=model,
                        messages=[{"role":m["role"],"content":m["content"]} for m in call_messages],
                        temperature=temperature, max_tokens=max_output_tokens, stream=True
                    )
                    response_text = st.write_stream(stream)
                st.session_state.messages.append({"role":"assistant","content":response_text})
                render_msg("assistant", response_text)
            else:
                with st.spinner("ìƒì„± ì¤‘â€¦"):
                    resp = client.chat.completions.create(
                        model=model,
                        messages=[{"role":m["role"],"content":m["content"]} for m in call_messages],
                        temperature=temperature, max_tokens=max_output_tokens, stream=False
                    )
                response_text = resp.choices[0].message.content
                st.session_state.messages.append({"role":"assistant","content":response_text})
                render_msg("assistant", response_text)
                if getattr(resp,"usage",None):
                    st.markdown(
                        f'<span class="badge">ğŸ§® tokens: {resp.usage.total_tokens} '
                        f'(in {resp.usage.prompt_tokens} / out {resp.usage.completion_tokens})</span>',
                        unsafe_allow_html=True
                    )
    except (AuthenticationError, RateLimitError, APIError) as e:
        st.error(f"OpenAI API ì˜¤ë¥˜: {e}")
    except Exception as e:
        st.exception(e)
