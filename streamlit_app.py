# app.py
import os
import io
import json
import numpy as np
import streamlit as st
from openai import OpenAI

# ì˜ˆì™¸ í´ë˜ìŠ¤ (í™˜ê²½ì— ë”°ë¼ ì„í¬íŠ¸ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ì•ˆì „ ê°€ë“œ)
try:
    from openai import APIError, RateLimitError, AuthenticationError
except Exception:
    APIError = RateLimitError = AuthenticationError = Exception

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ: PyPDF2ê°€ ì—†ìœ¼ë©´ TXTë§Œ ì§€ì›
try:
    import PyPDF2
    HAS_PYPDF2 = True
except Exception:
    HAS_PYPDF2 = False

# ----------------------------
# ê¸°ë³¸ ì„¸íŒ…
# ----------------------------
st.set_page_config(page_title="ğŸ’¬ ë‚˜ì˜ ì²«ë²ˆì§¸ Chatbot", page_icon="ğŸ’¬", layout="wide")
st.title("ğŸ’¬ ë‚˜ì˜ ì²«ë²ˆì§¸ Chatbot")

# ì„¸ì…˜ì˜ API í‚¤ ê¸°ë³¸ê°’ ìƒì„± (í™˜ê²½ë³€ìˆ˜/Secrets ìš°ì„ )
default_key = os.environ.get("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", None)
if "openai_api_key" not in st.session_state:
    st.session_state.openai_api_key = default_key  # ì—†ìœ¼ë©´ None

# ìƒë‹¨ ì•ˆë‚´ (í‚¤ ì—†ì„ ë•Œë§Œ)
if not st.session_state.openai_api_key:
    st.info("ğŸ”‘ **ì‚¬ì´ë“œë°”ì— OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.**", icon="ğŸ—ï¸")

# ----------------------------
# ì‚¬ì´ë“œë°”: ì„¤ì • (ì´ ë¸”ë¡ë§Œ ì‚¬ìš©)
# ----------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # API í‚¤ ì…ë ¥ (ì„¸ì…˜ ê¸°ë°˜)
    st.session_state.openai_api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        value=st.session_state.openai_api_key or "",
        help="í™˜ê²½ë³€ìˆ˜/Secretsê°€ ì—†ìœ¼ë©´ ì—¬ê¸°ì— ì…ë ¥"
    )

    model = st.selectbox(
        "Model",
        ["gpt-4o", "gpt-4o-mini"],
        index=0,
        help="ì¼ë°˜ ëŒ€í™”: gpt-4o / ë¹„ìš©ì ˆê°: gpt-4o-mini"
    )
    temperature = st.slider("Temperature(ì°½ì˜ì„±)", 0.0, 1.2, 0.7, 0.1)
    max_output_tokens = st.slider("Max output tokens(ì‘ë‹µ ê¸¸ì´)", 64, 4096, 1024, 64)
    stream_enable = st.toggle("ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°", value=True, help="ë„ë©´ ì‘ë‹µ í›„ í† í° ì‚¬ìš©ëŸ‰ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
    st.divider()

    st.subheader("Assistant ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹")
    preset = st.selectbox(
        "ë§íˆ¬/ì—­í•  í”„ë¦¬ì…‹",
        ["ê¸°ë³¸", "ì¹œì ˆí•œ íŠœí„°", "ì´ˆê°„ë‹¨ ìš”ì•½ë´‡", "ë¬¸ì¥ ë‹¤ë“¬ê¸°(êµì •)"],
        index=0
    )
    preset_map = {
        "ê¸°ë³¸": "You are a helpful, concise assistant.",
        "ì¹œì ˆí•œ íŠœí„°": "You are a friendly tutor. Explain step-by-step with small, clear paragraphs and examples.",
        "ì´ˆê°„ë‹¨ ìš”ì•½ë´‡": "You summarize any input into 3 bullet points with the most essential facts only.",
        "ë¬¸ì¥ ë‹¤ë“¬ê¸°(êµì •)": "Rewrite the user's text with improved clarity, grammar, and natural tone while preserving meaning."
    }
    system_prompt = st.text_area(
        "System prompt(ì„¸ë¶€ ì¡°ì • ê°€ëŠ¥)",
        value=preset_map.get(preset, preset_map["ê¸°ë³¸"]),
        height=100
    )

    st.subheader("ëŒ€í™” ê´€ë¦¬")
    max_turns_keep = st.slider("íˆìŠ¤í† ë¦¬ ë³´ì¡´ í„´(ì§ˆë¬¸/ë‹µë³€ ìŒ)", 5, 60, 30, 1)
    reset = st.button("ğŸ”„ ìƒˆ ëŒ€í™” ì‹œì‘")
    st.caption("ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ë¹„ìš©â†‘/ì†ë„â†“ â†’ ì˜¤ë˜ëœ ê¸°ë¡ì€ ìë™ íŠ¸ë¦¼")

# reset ì¦‰ì‹œ ì ìš©
if reset:
    st.session_state.clear()
    st.rerun()

# í‚¤/í´ë¼ì´ì–¸íŠ¸ í™•ì •
openai_api_key = st.session_state.openai_api_key
no_key = not openai_api_key
client = OpenAI(api_key=openai_api_key) if not no_key else None

# ì„¤ëª… ë°•ìŠ¤ (ì ‘ê¸°)
with st.expander("ì„¤ëª… ë³´ê¸°", expanded=False):
    st.markdown(
        "- OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. API í‚¤ëŠ” ì„¸ì…˜ì—ì„œë§Œ ì“°ì´ê³  ì„œë²„ì— ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
        "- ë°°í¬ ì‹œ **í™˜ê²½ë³€ìˆ˜** ë˜ëŠ” **Streamlit Secrets** ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
        "- ì—…ë¡œë“œ íŒŒì¼(PDF/TXT)ì€ ì„¸ì…˜ ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤."
    )

# ----------------------------
# ì „ì—­ UI í…Œë§ˆ (í°íŠ¸/ì¹´ë“œ/ë°°ì§€/ë§í’ì„ /ì¸í’‹ ê³ ì •)
# ----------------------------
st.markdown("""
<style>
:root {
  --brand-text:#222; --brand-accent:#5B8DEF;
  --bg-card:#fff; --bg-soft:#F6F8FB; --line-soft:rgba(0,0,0,.07); --radius-xl:16px;
}
html, body, [data-testid="stAppViewContainer"] {
  font-family: Pretendard, Inter, system-ui, -apple-system, "Segoe UI", Roboto, "Apple SD Gothic Neo", "Noto Sans KR", "Malgun Gothic", sans-serif;
  color: var(--brand-text);
}
h1,h2,h3 { letter-spacing:-.01em }
.block-container { padding-top: 1rem; padding-bottom:2.5rem; }
.ui-card{ background:var(--bg-card); border:1px solid var(--line-soft); border-radius:var(--radius-xl); box-shadow:0 6px 18px rgba(0,0,0,.04); padding:16px 18px; }
.ui-toolbar{ display:flex; align-items:center; gap:12px; }
.ui-toolbar .right{ margin-left:auto; display:flex; gap:8px; align-items:center; }
.badge{ display:inline-flex; align-items:center; gap:6px; background:var(--bg-soft); border:1px solid var(--line-soft); border-radius:999px; padding:4px 10px; font-size:12px;}
.chat-bubble{ border:1px solid var(--line-soft); border-radius:18px; padding:12px 14px; margin:6px 0; background:#fff;}
.chat-bubble.user{ background:#F1F6FF; border-color:rgba(45,116,255,.2); }
.chat-bubble.assist{ background:#F9FAFB; }
.chat-row{ display:flex; gap:10px; align-items:flex-start;}
.chat-avatar{ width:28px; height:28px; border-radius:50%; display:flex; align-items:center; justify-content:center; background:#EEF0F4; font-size:14px;}
div[data-testid="stChatInput"]{ position:sticky; bottom:0; z-index:10; background:rgba(255,255,255,.85); backdrop-filter:blur(6px); border-top:1px solid var(--line-soft);}
</style>
""", unsafe_allow_html=True)

# ----------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ----------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []  # [{"role":"system"/"user"/"assistant","content":...}]
    st.session_state.has_system = False
st.session_state.setdefault("rag_ready", False)
st.session_state.setdefault("rag_chunks", [])
st.session_state.setdefault("rag_embeds", None)    # np.array (N,D)
st.session_state.setdefault("rag_model", "text-embedding-3-small")
st.session_state.setdefault("use_rag", False)

# ----------------------------
# ë„ìš°ë¯¸ í•¨ìˆ˜
# ----------------------------
def ensure_system_message(prompt_text: str):
    if not st.session_state.has_system:
        st.session_state.messages.insert(0, {"role": "system", "content": prompt_text})
        st.session_state.has_system = True
    else:
        st.session_state.messages[0]["content"] = prompt_text

def trim_history(max_turns: int):
    msgs = st.session_state.messages
    if not msgs: return
    sys = msgs[0] if msgs and msgs[0]["role"] == "system" else None
    body = msgs[1:] if sys else msgs[:]
    limit = max_turns * 2
    if len(body) > limit: body = body[-limit:]
    st.session_state.messages = ([sys] if sys else []) + body

def extract_text_from_pdf(file_bytes: bytes) -> str:
    if not HAS_PYPDF2: return ""
    try:
        reader = PyPDF2.PdfReader(io.BytesIO(file_bytes))
        return "\n".join([(p.extract_text() or "") for p in reader.pages])
    except Exception:
        return ""

def chunk_text(text: str, chunk_size: int = 900, overlap: int = 200):
    text = " ".join(text.split())
    if not text: return []
    chunks, start = [], 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        if end >= len(text): break
        start = max(0, end - overlap)
    return chunks

def cosine_sim(A: np.ndarray, B: np.ndarray):
    A_norm = A / (np.linalg.norm(A, axis=1, keepdims=True) + 1e-12)
    B_norm = B / (np.linalg.norm(B, axis=1, keepdims=True) + 1e-12)
    return A_norm @ B_norm.T

def build_embeddings(client: OpenAI, chunks: list[str], embed_model: str) -> np.ndarray:
    if not chunks: return np.zeros((0, 1536), dtype=np.float32)
    resp = client.embeddings.create(model=embed_model, input=chunks)
    vecs = [d.embedding for d in resp.data]
    return np.array(vecs, dtype=np.float32)

def retrieve_context(query: str, top_k: int = 4) -> str:
    if not (st.session_state.rag_ready and st.session_state.rag_embeds is not None):
        return ""
    try:
        q_emb = client.embeddings.create(model=st.session_state.rag_model, input=[query]).data[0].embedding
        q_vec = np.array([q_emb], dtype=np.float32)
        sims = cosine_sim(q_vec, st.session_state.rag_embeds).flatten()
        idx = np.argsort(-sims)[:top_k]
        return "\n\n".join([st.session_state.rag_chunks[i] for i in idx])
    except Exception:
        return ""

def export_chat_as_txt(messages: list[dict]) -> bytes:
    lines = []
    for m in messages:
        r = m.get("role", "")
        if r == "system": continue
        lines.append(f"[{r.upper()}]\n{m.get('content','')}\n")
    return "\n".join(lines).encode("utf-8")

def export_chat_as_json(messages: list[dict]) -> bytes:
    payload = [m for m in messages if m.get("role") in ("user", "assistant")]
    return json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8")

# ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ ì•Œë¦¼
if no_key:
    st.warning("API í‚¤ê°€ ì—†ì–´ **ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ**ë¡œ ë™ì‘í•©ë‹ˆë‹¤. ì‘ë‹µ/ì„ë² ë”©ì€ ìƒì„±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ğŸ”’")

# ----------------------------
# í—¤ë” ë°” (ìƒíƒœ ë°°ì§€ + ë‚´ë³´ë‚´ê¸° ë²„íŠ¼)
# ----------------------------
st.markdown('<div class="ui-card ui-toolbar">', unsafe_allow_html=True)
st.markdown("### ğŸ’¬ ëŒ€í™” ì„¸ì…˜")
st.markdown(
    f'<span class="badge">Model: <b>{model}</b></span> '
    f'<span class="badge">Temp: <b>{float(temperature):.2f}</b></span>',
    unsafe_allow_html=True
)
st.markdown('<span class="right"></span>', unsafe_allow_html=True)

c1, c2 = st.columns([1,1])
with c1:
    st.download_button("TXT ë‚´ë³´ë‚´ê¸°", data=export_chat_as_txt(st.session_state.messages),
                       file_name="chat.txt", mime="text/plain", use_container_width=True)
with c2:
    st.download_button("JSON ë‚´ë³´ë‚´ê¸°", data=export_chat_as_json(st.session_state.messages),
                       file_name="chat.json", mime="application/json", use_container_width=True)
st.markdown('</div>', unsafe_allow_html=True)

# ----------------------------
# ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ (í† ê¸€ë¡œ ì—´ê³ /ë‹«ê¸°) + ì¹´ë“œ UI
# ----------------------------
if "show_upload" not in st.session_state:
    st.session_state.show_upload = False

st.session_state.show_upload = st.toggle("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ì—´ê¸°", value=st.session_state.show_upload)

if st.session_state.show_upload:
    st.markdown('<div class="ui-card">', unsafe_allow_html=True)
    st.markdown("#### ğŸ“ íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ) â€” PDF/TXT ì§€ì›, ì§ˆì˜Â·ì‘ë‹µì— í™œìš©")

    uploaded_files = st.file_uploader(
        "ì—¬ê¸°ì— PDFë‚˜ TXTë¥¼ ì˜¬ë¦¬ë©´, ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ í’ˆì§ˆì´ í–¥ìƒë¼ìš”. ì—¬ëŸ¬ íŒŒì¼ ê°€ëŠ¥.",
        type=["pdf", "txt"], accept_multiple_files=True
    )

    left, right = st.columns([3, 2])
    with left:
        use_rag = st.toggle("RAG ì‚¬ìš©", value=st.session_state.get("use_rag", False),
                            help="ì¼œë©´ ì—…ë¡œë“œ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©í•©ë‹ˆë‹¤.")
        st.session_state.use_rag = use_rag
    with right:
        _pad, btn = st.columns([1,1])
        with btn:
            rebuild = st.button("ğŸ“š ì¸ë±ìŠ¤ ìƒì„±/ì¬ìƒì„±", use_container_width=True)

    if rebuild and uploaded_files:
        if no_key:
            st.error("ì„ë² ë”© ìƒì„±ì—ëŠ” API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ğŸ”‘")
        else:
            all_text = []
            for f in uploaded_files:
                if f.type == "text/plain" or f.name.lower().endswith(".txt"):
                    text = f.read().decode("utf-8", errors="ignore")
                elif f.type == "application/pdf" or f.name.lower().endswith(".pdf"):
                    if not HAS_PYPDF2:
                        st.warning(f"'{f.name}' â†’ PyPDF2 ë¯¸ì„¤ì¹˜ë¡œ PDF ì¶”ì¶œ ë¶ˆê°€(TXTë§Œ ì§€ì›)."); text = ""
                    else:
                        text = extract_text_from_pdf(f.read())
                else:
                    text = ""
                if text: all_text.append(text)

            full_text = "\n\n".join(all_text)
            chunks = chunk_text(full_text, chunk_size=900, overlap=200)

            if not chunks:
                st.warning("ì¶”ì¶œ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤ìº” PDFëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ì„ ìˆ˜ ìˆì–´ìš”.")
            else:
                with st.spinner("ì„ë² ë”© ìƒì„± ì¤‘â€¦"):
                    vecs = build_embeddings(client, chunks, st.session_state.rag_model)
                st.session_state.rag_chunks = chunks
                st.session_state.rag_embeds = vecs
                st.session_state.rag_ready = True
                st.success(f"ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ! ì²­í¬ {len(chunks)}ê°œ")
    st.markdown('</div>', unsafe_allow_html=True)
else:
    # ì„¹ì…˜ ë‹«í ë•Œ ì„ íƒì ìœ¼ë¡œ RAG ìƒíƒœ ì´ˆê¸°í™”
    st.session_state.rag_ready = False
    st.session_state.rag_chunks = []
    st.session_state.rag_embeds = None

# ----------------------------
# ë§í’ì„  ë Œë”ëŸ¬ & ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ì¶œë ¥
# ----------------------------
def render_msg(role:str, content:str):
    kind = "user" if role=="user" else "assist"
    avatar = "ğŸ§‘â€ğŸ’»" if role=="user" else "ğŸ¤–"
    st.markdown(
        f'<div class="chat-row"><div class="chat-avatar">{avatar}</div>'
        f'<div class="chat-bubble {kind}">{content}</div></div>', unsafe_allow_html=True
    )

for m in st.session_state.messages:
    if m["role"] in ("user", "assistant"):
        render_msg(m["role"], m["content"])

# ë¹ˆ ìƒíƒœ ì•ˆë‚´
if not st.session_state.messages:
    st.markdown('<div class="ui-card">â“ ë¨¼ì € ì§ˆë¬¸ì„ ì…ë ¥í•´ ë³´ì„¸ìš”. ì˜ˆ) "ì´ PDFì˜ í•µì‹¬ ìš”ì•½ 3ì¤„"</div>', unsafe_allow_html=True)

# ----------------------------
# ì…ë ¥ & ì‘ë‹µ
# ----------------------------
user_input = st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? (Shift+Enter ì¤„ë°”ê¿ˆ)")
if user_input:
    ensure_system_message(system_prompt)
    trim_history(max_turns_keep)

    st.session_state.messages.append({"role":"user","content":user_input})
    render_msg("user", user_input)

    # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸
    additional_context = ""
    if st.session_state.get("use_rag", False):
        ctx = retrieve_context(user_input, top_k=4)
        if ctx:
            additional_context = (
                "Use the following context from user's documents when relevant.\n\n"
                f"=== BEGIN CONTEXT ===\n{ctx}\n=== END CONTEXT ==="
            )

    try:
        call_messages = list(st.session_state.messages)
        if additional_context:
            call_messages.append({"role":"user","content":additional_context})

        if no_key:
            render_msg("assistant", "ğŸ”’ ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ: API í‚¤ë¥¼ ì…ë ¥í•˜ë©´ ì‹¤ì œ ë‹µë³€ì´ ìƒì„±ë©ë‹ˆë‹¤.")
        else:
            if stream_enable:
                stream = client.chat.completions.create(
                    model=model,
                    messages=[{"role": m["role"], "content": m["content"]} for m in call_messages],
                    temperature=temperature,
                    max_tokens=max_output_tokens,
                    stream=True,
                )
                with st.spinner("ìƒì„± ì¤‘â€¦"):
                    response_text = st.write_stream(stream)
                st.session_state.messages.append({"role":"assistant","content":response_text})
                render_msg("assistant", response_text)
            else:
                resp = client.chat.completions.create(
                    model=model,
                    messages=[{"role": m["role"], "content": m["content"]} for m in call_messages],
                    temperature=temperature,
                    max_tokens=max_output_tokens,
                    stream=False,
                )
                response_text = resp.choices[0].message.content
                st.session_state.messages.append({"role":"assistant","content":response_text})
                render_msg("assistant", response_text)
                if getattr(resp, "usage", None):
                    in_tok = resp.usage.prompt_tokens
                    out_tok = resp.usage.completion_tokens
                    tot_tok = resp.usage.total_tokens
                    st.markdown(f'<span class="badge">ğŸ§® tokens: {tot_tok} (in {in_tok} / out {out_tok})</span>', unsafe_allow_html=True)

    except (AuthenticationError, RateLimitError, APIError) as e:
        st.error(f"OpenAI API ì˜¤ë¥˜: {e}")
    except Exception as e:
        st.exception(e)
